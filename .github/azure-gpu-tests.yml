# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
  tags:
    include:
      - '*'
  branches:
    include:
      - "main"
      - "refs/tags/*"

pr:
  branches:
    include:
      - "main"

jobs:
  - job: testing
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "20"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"
    pool: "lit-rtx-3090"
    variables:
      DEVICES: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )
    container:
      image: "pytorchlightning/pytorch_lightning:base-cuda-py3.10-torch2.0-cuda11.7.1"
      options: "--gpus=all --shm-size=8gb"
    workspace:
      clean: all
    steps:

    - bash: |
        echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
        cuda_ver=$(python -c "import torch ; print(''.join(map(str, torch.version.cuda.split('.')[:2])))")
        echo "##vso[task.setvariable variable=CUDA_VERSION_MM]$cuda_ver"
      displayName: 'set env. vars'

    - bash: |
        echo $CUDA_VISIBLE_DEVICES
        echo $CUDA_VERSION_MM
        lspci | egrep 'VGA|3D'
        whereis nvidia
        nvidia-smi
        which python && which pip
        python --version && pip --version && pip list
        python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu == 2, f'GPU: {mgpu}'"
      displayName: 'Image info & NVIDIA'

    - script: pip install pytest -r requirements.txt
      displayName: 'Install dependencies'

    - bash: pytest -v --durations=10 --disable-pytest-warnings --strict-markers --color=yes
      displayName: 'Testing'
